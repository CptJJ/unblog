import { html2md } from "@/lib/crawler/html2md";
import { crawlSiteMap, findSideMapUrl } from "@/lib/crawler/sitemap";
import { client } from "@/trigger";
import { invokeTrigger } from "@trigger.dev/sdk";
import { z } from "zod";
import { parseUrlJob } from "./parse-url";
// Your first job
// This Job will be triggered by an event, log a joke to the console, and then wait 5 seconds before logging the punchline.
export const crawlSiteJob = client.defineJob({
  // This is the unique identifier for your Job, it must be unique across all Jobs in your project.
  id: "crawl-site",
  name: "Crawls a site, parsing the HTML to markdown collecting metadata",
  version: "0.0.1",
  // This is triggered by an event using eventTrigger. You can also trigger Jobs with webhooks, on schedules, and more: https://trigger.dev/docs/documentation/concepts/triggers/introduction
  trigger: invokeTrigger(),

  run: async (payload, io, ctx) => {
    // Use a Task to generate a random number. Using a Tasks means it only runs once.
    const siteMapUrl = await io.runTask("find-site-map", async () => {
      return await findSideMapUrl(payload.url);
    });
    if (!siteMapUrl) {
      throw new Error("Sitemap not found");
    }

    await io.logger.info(`Site map url found: ${siteMapUrl}`);

    const pages = await io.runTask("crawl-site-map", async () => {
      return await crawlSiteMap(siteMapUrl);
    });
    if (!pages || pages.length === 0) {
      throw new Error("Sitemap not able to be parsed");
    }

    await io.logger.info(`Total number of pages found: ${pages.length}`);

    const runs = await parseUrlJob.batchInvokeAndWaitForCompletion(
      "âš¡",
      pages.slice(0, 10).map((page) => ({
        payload: {
          url: page,
        },
        timeoutInSeconds: 60,
      })),
    );
  },
});
